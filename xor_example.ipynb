{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR operation by NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.694192 [[ 0.38814735 -0.20966713]\n",
      " [ 0.1806348  -0.375875  ]] [[-0.44491372]\n",
      " [ 0.70176834]]\n",
      "1000 0.693339 [[ 0.32086322 -0.07168127]\n",
      " [ 0.07590109 -0.27049291]] [[-0.41793168]\n",
      " [ 0.61851215]]\n",
      "2000 0.69322 [[ 0.29030085 -0.00923738]\n",
      " [ 0.01765184 -0.22450809]] [[-0.40088201]\n",
      " [ 0.59317988]]\n",
      "3000 0.69318 [[ 0.27482644  0.02630654]\n",
      " [-0.02019913 -0.19851612]] [[-0.39234942]\n",
      " [ 0.58106726]]\n",
      "4000 0.693162 [[ 0.26721501  0.04954347]\n",
      " [-0.04742356 -0.18198174]] [[-0.38752374]\n",
      " [ 0.57454139]]\n",
      "5000 0.693152 [[ 0.26464677  0.06638727]\n",
      " [-0.0686458  -0.1711266 ]] [[-0.3846783 ]\n",
      " [ 0.57098961]]\n",
      "6000 0.693143 [[ 0.26596051  0.07975778]\n",
      " [-0.08650951 -0.16434366]] [[-0.38314295]\n",
      " [ 0.56933081]]\n",
      "7000 0.693135 [[ 0.27079007  0.09132771]\n",
      " [-0.10277356 -0.16093186]] [[-0.38270462]\n",
      " [ 0.56909269]]\n",
      "8000 0.693126 [[ 0.27926892  0.10221041]\n",
      " [-0.11880027 -0.16067655]] [[-0.38341314]\n",
      " [ 0.57011634]]\n",
      "[array([[ 0.50291359],\n",
      "       [ 0.50005174],\n",
      "       [ 0.49992329],\n",
      "       [ 0.49700138]], dtype=float32), array([[ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.]], dtype=float32), array([[False],\n",
      "       [ True],\n",
      "       [False],\n",
      "       [ True]], dtype=bool), 0.5]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Implement code for Sung Kim's TF lecture. See https://www.youtube.com/watch?v=9i7FBbcZPMA&feature=youtu.be\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "# Need to change data structure. THESE LINES ARE DIFFERNT FROM Video BUT IT MAKES THIS CODE WORKS!\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform( [2,2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [2,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 'wide' neural network to solve XOR problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.733474 [[ 0.70221001 -0.53889644  0.11911839 -0.86905229 -0.93228507 -0.8713544\n",
      "  -0.54055244  0.57190865 -0.25249514 -0.40831131]\n",
      " [-0.5210098   0.75651574  0.43360707  0.75772208  0.61628681 -0.37962148\n",
      "   0.90395856  0.04139151 -0.48191801 -0.17461844]] [[-0.93642765]\n",
      " [ 0.65975887]\n",
      " [-0.42310634]\n",
      " [ 0.52158654]\n",
      " [-0.56722403]\n",
      " [-0.73981887]\n",
      " [-0.72574544]\n",
      " [ 0.79894501]\n",
      " [-0.34472358]\n",
      " [ 0.29835099]]\n",
      "1000 0.629403 [[ 1.07106316 -0.85133737  0.05937625 -1.42341197 -0.78972965 -1.63911951\n",
      "  -0.83708769  0.74785751 -0.34079257 -0.36304   ]\n",
      " [-0.50998515  0.55439878  0.46740225  0.79922533  0.95587134 -1.3901459\n",
      "   1.56642306  0.36407518 -0.50718886 -0.17423981]] [[-0.82659197]\n",
      " [ 0.86280787]\n",
      " [-0.27249357]\n",
      " [ 1.04360044]\n",
      " [-0.57415181]\n",
      " [-1.43375754]\n",
      " [-1.13861907]\n",
      " [ 1.08004034]\n",
      " [-0.14067982]\n",
      " [ 0.52612907]]\n",
      "2000 0.262367 [[ 1.71268225 -1.69308043  0.06929957 -3.06719041 -1.01242387 -3.18095994\n",
      "  -2.38301849  1.43026102 -0.34650099 -0.45042449]\n",
      " [-0.79469007  0.81020445  0.54038388  2.04301095  1.76457906 -3.03913975\n",
      "   3.45929193  1.20639384 -0.52859384 -0.39317867]] [[-1.02411127]\n",
      " [ 1.62565374]\n",
      " [-0.15973046]\n",
      " [ 3.01800418]\n",
      " [-1.14011371]\n",
      " [-3.4518404 ]\n",
      " [-3.29046512]\n",
      " [ 1.78995252]\n",
      " [ 0.34937912]\n",
      " [ 1.06449401]]\n",
      "3000 0.0809608 [[ 2.10825896 -2.3934536   0.08344013 -4.21523952 -1.35534    -3.89452887\n",
      "  -3.38022733  1.83568847 -0.34781608 -0.5614723 ]\n",
      " [-0.98707938  1.2020179   0.5771383   2.96263742  2.39433098 -3.74124408\n",
      "   4.65825176  1.6290729  -0.61829597 -0.66941917]] [[-1.22342372]\n",
      " [ 2.34953141]\n",
      " [-0.11676726]\n",
      " [ 4.72091961]\n",
      " [-1.73138297]\n",
      " [-4.43558121]\n",
      " [-5.15409184]\n",
      " [ 2.36457825]\n",
      " [ 0.76323587]\n",
      " [ 1.5772481 ]]\n",
      "4000 0.0402157 [[ 2.29533124 -2.76395416  0.088029   -4.69842052 -1.56936777 -4.18372297\n",
      "  -3.80527663  2.01352763 -0.34916008 -0.61820543]\n",
      " [-1.09107959  1.44962704  0.5902015   3.37040281  2.73442769 -4.02068186\n",
      "   5.14884567  1.80699837 -0.68868518 -0.8319754 ]] [[-1.33576083]\n",
      " [ 2.7628696 ]\n",
      " [-0.09783725]\n",
      " [ 5.56958055]\n",
      " [-2.09577632]\n",
      " [-4.86744738]\n",
      " [-6.07609129]\n",
      " [ 2.65509796]\n",
      " [ 0.9758392 ]\n",
      " [ 1.86847937]]\n",
      "5000 0.0253612 [[ 2.40967655 -2.99620605  0.09026824 -4.96834946 -1.71213758 -4.34677982\n",
      "  -4.04669237  2.11832929 -0.35037971 -0.65934521]\n",
      " [-1.158916    1.61593425  0.59677148  3.60571241  2.95098662 -4.17821789\n",
      "   5.42030525  1.91115677 -0.73969752 -0.94043964]] [[-1.41235733]\n",
      " [ 3.036731  ]\n",
      " [-0.08679573]\n",
      " [ 6.08728981]\n",
      " [-2.34335876]\n",
      " [-5.12328768]\n",
      " [-6.63479996]\n",
      " [ 2.83422112]\n",
      " [ 1.10969782]\n",
      " [ 2.06127787]]\n",
      "6000 0.0180829 [[ 2.49044871 -3.16072679  0.09162534 -5.14740419 -1.81737113 -4.45612144\n",
      "  -4.20868921  2.19084978 -0.351726   -0.69329983]\n",
      " [-1.20869708  1.73853588  0.60080498  3.76496005  3.10595226 -4.28402805\n",
      "   5.59943628  1.98311615 -0.77906084 -1.02085114]] [[-1.47039711]\n",
      " [ 3.23885465]\n",
      " [-0.07928962]\n",
      " [ 6.44986105]\n",
      " [-2.52833891]\n",
      " [-5.30052662]\n",
      " [-7.02432632]\n",
      " [ 2.96070313]\n",
      " [ 1.20579767]\n",
      " [ 2.20409751]]\n",
      "7000 0.013867 [[ 2.55234742 -3.28627992  0.09255107 -5.27832174 -1.90011239 -4.53683281\n",
      "  -4.32814264  2.24571323 -0.35319039 -0.7227639 ]\n",
      " [-1.24783957  1.83469462  0.60357863  3.88300371  3.22507238 -4.36224365\n",
      "   5.72997141  2.03752685 -0.8109749  -1.0844419 ]] [[-1.51711428]\n",
      " [ 3.39810991]\n",
      " [-0.07371736]\n",
      " [ 6.72520542]\n",
      " [-2.67521405]\n",
      " [-5.43447161]\n",
      " [-7.31925488]\n",
      " [ 3.05743122]\n",
      " [ 1.28026235]\n",
      " [ 2.31725502]]\n",
      "8000 0.0111533 [[ 2.60227728 -3.38689041  0.09323078 -5.38008451 -1.96802294 -4.60008097\n",
      "  -4.42160606  2.28959036 -0.35473183 -0.74900079]\n",
      " [-1.28001404  1.91334891  0.60562593  3.97569036  3.32105947 -4.42361593\n",
      "   5.83119965  2.08102965 -0.83777308 -1.13690639]] [[-1.55620873]\n",
      " [ 3.52907062]\n",
      " [-0.06934295]\n",
      " [ 6.94545078]\n",
      " [-2.79667592]\n",
      " [-5.54136086]\n",
      " [-7.55467176]\n",
      " [ 3.13528347]\n",
      " [ 1.34083796]\n",
      " [ 2.41089559]]\n",
      "[array([[ 0.00605645],\n",
      "       [ 0.98954356],\n",
      "       [ 0.98732275],\n",
      "       [ 0.01515269]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use 'wide' neural network (10 neurals) to solve XOR problem. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Wide network: Use more neurons in each layer. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 'Deep' neural network to solve XOR problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.721231 [[-0.18185458  0.63436347  0.98922336  0.57007366 -0.03416014]\n",
      " [ 0.561068   -0.77762485 -0.84238166 -0.46791831  0.80516267]] [[ 0.1613846  -0.19442379  0.11019868 -0.47708055]\n",
      " [ 0.46501455 -0.41790804 -0.67535931  0.21991305]\n",
      " [-0.42998701 -0.73683506  0.9118821   0.5156315 ]\n",
      " [ 0.58294934 -0.79343522  0.7976166  -0.13877687]\n",
      " [-0.27826256 -0.43033704  0.41770962 -0.14359935]]\n",
      "1000 0.690814 [[ -1.84638709e-01   7.67681837e-01   8.75721753e-01   5.94293296e-01\n",
      "    3.85065534e-04]\n",
      " [  5.74159026e-01  -7.36427665e-01  -1.05523765e+00  -4.59358811e-01\n",
      "    8.08623910e-01]] [[ 0.18169942 -0.1852659   0.09747643 -0.50821173]\n",
      " [ 0.52221298 -0.44674158 -0.74510795  0.19449112]\n",
      " [-0.43110609 -0.76135391  0.88575405  0.52451724]\n",
      " [ 0.63008791 -0.81463087  0.74210912 -0.16305436]\n",
      " [-0.26150265 -0.4186874   0.41168559 -0.1738344 ]]\n",
      "2000 0.683271 [[-0.1973902   1.02923679  1.02841508  0.61634266  0.05312655]\n",
      " [ 0.58164006 -0.79080409 -1.45131207 -0.47987288  0.81781423]] [[ 0.15550624 -0.17224358  0.07304733 -0.52941066]\n",
      " [ 0.62285048 -0.5043155  -0.89153814  0.1443349 ]\n",
      " [-0.63147229 -0.77303201  1.02356935  0.64666057]\n",
      " [ 0.64633393 -0.84743029  0.67739344 -0.17414975]\n",
      " [-0.30504215 -0.40238374  0.39801553 -0.18696256]]\n",
      "3000 0.589527 [[-0.21626376  1.79838645  2.02445626  0.63999051  0.17876519]\n",
      " [ 0.57916278 -1.41156578 -2.49041152 -0.53038812  0.89125282]] [[ 0.01871882 -0.1524287   0.08193989 -0.54731017]\n",
      " [ 1.0317663  -0.64131224 -1.46984446 -0.09429535]\n",
      " [-1.43648338 -0.75527328  1.76370752  1.07703435]\n",
      " [ 0.62788224 -0.90203381  0.56937617 -0.19927613]\n",
      " [-0.50030947 -0.3783932   0.44989023 -0.17752196]]\n",
      "4000 0.0762566 [[-0.2512719   3.79963183  3.80311632  0.7080099   0.52975219]\n",
      " [ 0.60704517 -3.33274937 -4.24297523 -0.59122896  1.2922219 ]] [[-0.32544458 -0.10277414  0.44627616 -0.43537077]\n",
      " [ 2.85312247 -0.90485358 -3.38012505 -0.85823458]\n",
      " [-3.24492478 -0.70485294  3.52074504  1.92550981]\n",
      " [ 0.64252603 -0.95197225  0.52352858 -0.20033023]\n",
      " [-0.99865359 -0.31845722  0.96801549  0.01450739]]\n",
      "5000 0.0215869 [[-0.27292973  4.35027456  4.20909548  0.72987175  0.71234614]\n",
      " [ 0.60653061 -3.80703378 -4.69245291 -0.60368919  1.42849505]] [[-0.40528741 -0.08633416  0.53098357 -0.37586489]\n",
      " [ 3.46719837 -0.98871517 -3.98402596 -1.14927721]\n",
      " [-3.83309364 -0.68782806  4.06194115  2.1987226 ]\n",
      " [ 0.62704545 -0.96202868  0.53313118 -0.18391776]\n",
      " [-1.14233351 -0.29768813  1.11212122  0.11519926]]\n",
      "6000 0.0115527 [[-0.28384277  4.57205248  4.37109709  0.73986739  0.79963857]\n",
      " [ 0.60214871 -3.9969182  -4.87817335 -0.60883886  1.48951221]] [[-0.43597743 -0.07856821  0.56271338 -0.34660488]\n",
      " [ 3.73258424 -1.02704263 -4.23851967 -1.29332256]\n",
      " [-4.09125614 -0.68001276  4.29543543  2.32407165]\n",
      " [ 0.61924422 -0.96622062  0.53846723 -0.17698023]\n",
      " [-1.20472753 -0.28767067  1.1725924   0.16641293]]\n",
      "7000 0.00769226 [[-0.29106158  4.70384121  4.46731472  0.74620545  0.85503465]\n",
      " [ 0.59822351 -4.10965919 -4.98975563 -0.61204147  1.52777863]] [[-0.45388508 -0.07351948  0.58100027 -0.32747945]\n",
      " [ 3.89537168 -1.05146837 -4.39290285 -1.388623  ]\n",
      " [-4.25066996 -0.67502922  4.43862438  2.40388227]\n",
      " [ 0.61427456 -0.96878415  0.54195815 -0.17297448]\n",
      " [-1.24344015 -0.28107908  1.20955455  0.20046939]]\n",
      "8000 0.00570119 [[-0.2964482   4.79559278  4.53434038  0.75081068  0.89507824]\n",
      " [ 0.59486896 -4.1881156  -5.06795549 -0.61435491  1.55535257]] [[-0.46621349 -0.06978331  0.59349352 -0.31334069]\n",
      " [ 4.01091099 -1.06930625 -4.50174713 -1.45982814]\n",
      " [-4.36433029 -0.67138743  4.540308    2.46210742]\n",
      " [ 0.61067915 -0.97060877  0.54452062 -0.17028512]\n",
      " [-1.27117038 -0.27616078  1.23579836  0.22593549]]\n",
      "[array([[ 0.00538983],\n",
      "       [ 0.99394482],\n",
      "       [ 0.99532193],\n",
      "       [ 0.00661573]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use 'Deep' neural network to solve XOR problem. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0))\n",
    "\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias1\")\n",
    "\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
