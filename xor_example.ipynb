{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR operation by NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.710807 [[-0.23799537 -0.64334887]\n",
      " [ 0.99189657  0.35737014]] [[ 0.00626673]\n",
      " [ 0.81748635]]\n",
      "1000 0.69128 [[-0.3450323  -0.79193425]\n",
      " [ 1.05605483  0.44133425]] [[-0.28741881]\n",
      " [ 0.76176196]]\n",
      "2000 0.677758 [[-0.62844026 -1.28290963]\n",
      " [ 1.27633893  0.90647316]] [[-0.62846887]\n",
      " [ 1.15018058]]\n",
      "3000 0.453673 [[-2.06531715 -3.04426694]\n",
      " [ 2.50935221  2.75427008]] [[-2.33258724]\n",
      " [ 3.2621007 ]]\n",
      "4000 0.135482 [[-4.00421095 -4.55536938]\n",
      " [ 4.30133009  4.35006046]] [[-5.21226311]\n",
      " [ 5.92975426]]\n",
      "5000 0.0639115 [[-4.778584   -5.1712079 ]\n",
      " [ 5.05409527  4.97500181]] [[-6.70084286]\n",
      " [ 7.32425356]]\n",
      "6000 0.0401752 [[-5.18592644 -5.50901747]\n",
      " [ 5.45449162  5.31195784]] [[-7.58791351]\n",
      " [ 8.1762228 ]]\n",
      "7000 0.0289248 [[-5.45069551 -5.73371077]\n",
      " [ 5.71594238  5.5343771 ]] [[-8.20870018]\n",
      " [ 8.77964783]]\n",
      "8000 0.022471 [[-5.64311171 -5.89939642]\n",
      " [ 5.90645838  5.69770765]] [[-8.68360901]\n",
      " [ 9.24435234]]\n",
      "[array([[ 0.02181667],\n",
      "       [ 0.98046219],\n",
      "       [ 0.97081202],\n",
      "       [ 0.01830276]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Implement code for Sung Kim's TF lecture. See https://www.youtube.com/watch?v=9i7FBbcZPMA&feature=youtu.be\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "# Need to change data structure. THESE LINES ARE DIFFERNT FROM Video BUT IT MAKES THIS CODE WORKS!\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform( [2,2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [2,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 'wide' 10 neurals network to solve XOR problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.698332 [[ 0.96428281 -0.12110915 -0.31592286  0.76239818 -0.69043756 -0.97537237\n",
      "   0.55899614  0.18925501 -0.84202445  0.07934161]\n",
      " [ 0.24333893  0.01567234 -0.70100856  0.53511059  0.37110645  0.82214242\n",
      "  -0.02609664 -0.21773313  0.90476358 -0.55190843]] [[-0.85513866]\n",
      " [-0.01900747]\n",
      " [ 0.96581256]\n",
      " [ 0.5512079 ]\n",
      " [ 0.04411528]\n",
      " [ 0.36710292]\n",
      " [-0.82939547]\n",
      " [ 0.86053824]\n",
      " [-0.50499928]\n",
      " [ 0.09310402]]\n",
      "1000 0.625351 [[ 0.9742502  -0.12143259 -0.00807752  1.74074697 -0.68707424 -1.32227337\n",
      "   0.61815172  0.21211752 -1.00341845  0.08500257]\n",
      " [-0.23306109  0.01406289 -0.57828975  1.66302443  0.37282851  0.83871174\n",
      "  -0.20501171 -0.20546037  1.52710509 -0.54845244]] [[-0.93262035]\n",
      " [-0.13510767]\n",
      " [ 0.77094966]\n",
      " [ 1.66649032]\n",
      " [-0.02218213]\n",
      " [ 0.67374319]\n",
      " [-0.95231545]\n",
      " [ 0.75435144]\n",
      " [-1.18097603]\n",
      " [-0.02579555]]\n",
      "2000 0.260651 [[ 1.81638861 -0.05677377 -0.16886614  3.49939966 -0.74043673 -2.69569921\n",
      "   1.28675354 -0.0903553  -2.55314016  0.06836709]\n",
      " [-0.6281994   0.06073546 -0.81414461  3.55438995  0.34157404  1.66431677\n",
      "  -0.30387324 -0.48737857  3.56387973 -0.56346262]] [[-1.6750437 ]\n",
      " [-0.10035264]\n",
      " [ 1.03563094]\n",
      " [ 4.1800828 ]\n",
      " [ 0.23601055]\n",
      " [ 2.42608929]\n",
      " [-1.39748943]\n",
      " [ 0.8602547 ]\n",
      " [-3.63244653]\n",
      " [ 0.14513876]]\n",
      "3000 0.0848288 [[ 2.55762124 -0.03634273 -0.26382846  4.2889781  -0.87201929 -3.84373212\n",
      "   1.79391551 -0.23438942 -3.56685472  0.0101205 ]\n",
      " [-1.03291118  0.08049794 -1.0458256   4.30926991  0.24795426  2.498245\n",
      "  -0.44644538 -0.70966333  4.81747627 -0.64421004]] [[-2.31777048]\n",
      " [-0.02256086]\n",
      " [ 1.44072545]\n",
      " [ 5.49566841]\n",
      " [ 0.49934116]\n",
      " [ 4.02580786]\n",
      " [-1.74357748]\n",
      " [ 1.15523505]\n",
      " [-5.65197659]\n",
      " [ 0.40564555]]\n",
      "4000 0.0431667 [[ 2.92959166 -0.0362095  -0.28303581  4.62292147 -0.94851083 -4.35980225\n",
      "   2.038481   -0.26532775 -4.01574421 -0.02333348]\n",
      " [-1.27485681  0.0805844  -1.19762337  4.60511541  0.18620124  2.90843415\n",
      "  -0.5367099  -0.83957946  5.35061932 -0.71571207]] [[-2.65525317]\n",
      " [ 0.02194877]\n",
      " [ 1.69466949]\n",
      " [ 6.10881138]\n",
      " [ 0.63609177]\n",
      " [ 4.84743547]\n",
      " [-1.90432966]\n",
      " [ 1.34515953]\n",
      " [-6.71951532]\n",
      " [ 0.56834102]]\n",
      "5000 0.0276376 [[ 3.15741634 -0.03864021 -0.29222387  4.81426001 -0.99651188 -4.65414619\n",
      "   2.18995309 -0.27394107 -4.27547407 -0.04249365]\n",
      " [-1.43769419  0.07687534 -1.30539894  4.7721796   0.1463851   3.15546966\n",
      "  -0.60162121 -0.92868495  5.65134287 -0.77027857]] [[-2.87616658]\n",
      " [ 0.05074416]\n",
      " [ 1.86854851]\n",
      " [ 6.47964048]\n",
      " [ 0.72277296]\n",
      " [ 5.35796928]\n",
      " [-2.00492406]\n",
      " [ 1.47513187]\n",
      " [-7.38853121]\n",
      " [ 0.67759299]]\n",
      "6000 0.0199237 [[ 3.31716847 -0.04138277 -0.29968831  4.94370794 -1.03025424 -4.85153294\n",
      "   2.29801416 -0.27635026 -4.45199823 -0.05458885]\n",
      " [-1.5589112   0.07247318 -1.38775945  4.8849721   0.11834398  3.32700396\n",
      "  -0.6527639  -0.99621123  5.8518672  -0.81335652]] [[-3.0398128 ]\n",
      " [ 0.07165737]\n",
      " [ 1.99927378]\n",
      " [ 6.73985195]\n",
      " [ 0.78498936]\n",
      " [ 5.72038078]\n",
      " [-2.07822633]\n",
      " [ 1.57284367]\n",
      " [-7.86437607]\n",
      " [ 0.75844383]]\n",
      "7000 0.0154099 [[ 3.43848801 -0.04401575 -0.30676201  5.03985357 -1.05577183 -4.9968667\n",
      "   2.38144588 -0.27663535 -4.58346891 -0.06274578]\n",
      " [-1.65497553  0.06810821 -1.45388877  4.96884966  0.09724935  3.45650983\n",
      "  -0.69519758 -1.05050564  5.99893522 -0.84868282]] [[-3.16967702]\n",
      " [ 0.08797323]\n",
      " [ 2.10356617]\n",
      " [ 6.93848181]\n",
      " [ 0.83301157]\n",
      " [ 5.99854708]\n",
      " [-2.13605785]\n",
      " [ 1.65085912]\n",
      " [-8.22962475]\n",
      " [ 0.8221795 ]]\n",
      "8000 0.0124813 [[ 3.53546429 -0.04645524 -0.31368354  5.11557531 -1.07603371 -5.11040068\n",
      "   2.44913578 -0.27614132 -4.68718767 -0.06848986]\n",
      " [-1.73432207  0.06397106 -1.50884223  5.03504658  0.08062035  3.55965805\n",
      "  -0.73158509 -1.09587383  6.11348391 -0.87853074]] [[-3.27729344]\n",
      " [ 0.10130817]\n",
      " [ 2.19012737]\n",
      " [ 7.09834623]\n",
      " [ 0.87185574]\n",
      " [ 6.22299576]\n",
      " [-2.18392324]\n",
      " [ 1.71568489]\n",
      " [-8.52417755]\n",
      " [ 0.87459135]]\n",
      "[array([[ 0.00657796],\n",
      "       [ 0.98864377],\n",
      "       [ 0.98602134],\n",
      "       [ 0.0176689 ]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use 'wide' 10 neurals network to solve XOR problem. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Wide network: Use more neurons in each layer. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 'Deep' neurals network to solve XOR problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.712705 [[-0.59350902 -0.67372859  0.51656502 -0.58937883  0.16740671]\n",
      " [ 0.44365084 -0.85480618 -0.56178772  0.39537501  0.00100397]] [[ 0.09966767  0.27328455  0.57515174  0.64497215]\n",
      " [-0.36029056 -0.83498359 -0.92396492 -0.90298247]\n",
      " [ 0.27738696 -0.63415033  0.58206475  0.45997095]\n",
      " [-0.86903203  0.68250346  0.03744411 -0.82934904]\n",
      " [-0.71550012 -0.75235897  0.57310534  0.88734448]]\n",
      "1000 0.692316 [[-0.60306162 -0.71467155  0.52749366 -0.59106761  0.17790778]\n",
      " [ 0.44007629 -0.8949843  -0.56116164  0.40749621  0.00812146]] [[ 0.08650257  0.27103561  0.57885695  0.64066291]\n",
      " [-0.38364092 -0.86036581 -0.90914267 -0.9202643 ]\n",
      " [ 0.27332133 -0.65346545  0.58555984  0.45384622]\n",
      " [-0.88189089  0.68000591  0.04122877 -0.83374399]\n",
      " [-0.72589868 -0.76709533  0.57675767  0.88153666]]\n",
      "2000 0.691883 [[-0.61373061 -0.77513069  0.54033595 -0.59614438  0.18840498]\n",
      " [ 0.43748003 -0.95310426 -0.56095886  0.4191606   0.01371179]] [[ 0.08156946  0.27835953  0.58021683  0.64135718]\n",
      " [-0.40486252 -0.88683116 -0.89665842 -0.93934876]\n",
      " [ 0.27805617 -0.66695255  0.58677715  0.45231432]\n",
      " [-0.88709748  0.68644398  0.04278857 -0.83342594]\n",
      " [-0.72732121 -0.7743783   0.57794082  0.88081497]]\n",
      "3000 0.691159 [[-0.62783593 -0.86100477  0.55620688 -0.60328299  0.20204206]\n",
      " [ 0.43456721 -1.03425634 -0.56063384  0.43216899  0.02058088]] [[ 0.07662648  0.28812197  0.58146209  0.64193749]\n",
      " [-0.43183944 -0.92359722 -0.88598365 -0.96749324]\n",
      " [ 0.28309932 -0.68321848  0.58801854  0.44979188]\n",
      " [-0.89298421  0.69442123  0.04430168 -0.83365273]\n",
      " [-0.72886539 -0.78302515  0.57912135  0.87941068]]\n",
      "4000 0.689869 [[-0.64702851 -0.98226178  0.57615495 -0.61292756  0.21981193]\n",
      " [ 0.43132564 -1.14768422 -0.56004018  0.44699782  0.02916336]] [[ 0.07182114  0.30173931  0.58236694  0.64217609]\n",
      " [-0.46788669 -0.97716016 -0.87872249 -1.01098859]\n",
      " [ 0.28860965 -0.70287877  0.58901179  0.44550559]\n",
      " [-0.89968038  0.70476466  0.04544933 -0.83502954]\n",
      " [-0.73056215 -0.79326665  0.58006078  0.87665641]]\n",
      "5000 0.687429 [[-0.67438477 -1.15291584  0.60188603 -0.62571239  0.24320458]\n",
      " [ 0.42761761 -1.30669057 -0.55895144  0.46462879  0.04006143]] [[ 0.06750366  0.32193643  0.58244663  0.64171988]\n",
      " [-0.51819408 -1.05881083 -0.878084   -1.08123803]\n",
      " [ 0.29491642 -0.72663885  0.5890975   0.43809584]\n",
      " [-0.90734017  0.71907771  0.04554871 -0.83871353]\n",
      " [-0.73241919 -0.80528629  0.58014119  0.87126935]]\n",
      "6000 0.68251 [[-0.71610779 -1.39266002  0.6363703  -0.64251065  0.27460417]\n",
      " [ 0.42286125 -1.53026307 -0.55693108  0.48721564  0.05417746]] [[ 0.06455058  0.35433203  0.58082461  0.64057338]\n",
      " [-0.59074408 -1.18761861 -0.88982785 -1.19869816]\n",
      " [ 0.30270836 -0.75504905  0.58695483  0.42555773]\n",
      " [-0.91613179  0.74058312  0.04324577 -0.84661382]\n",
      " [-0.73440862 -0.81906027  0.57806605  0.8610673 ]]\n",
      "7000 0.671817 [[-0.78597301 -1.73184037  0.68526429 -0.66437948  0.31827807]\n",
      " [ 0.41492996 -1.84724426 -0.55251145  0.5195362   0.07351743]] [[ 0.06530996  0.41121355  0.57624418  0.64213526]\n",
      " [-0.69742572 -1.39395034 -0.92339504 -1.39844394]\n",
      " [ 0.3133733  -0.78779274  0.58019239  0.40676492]\n",
      " [-0.92621797  0.77557117  0.03603978 -0.86035311]\n",
      " [-0.73656636 -0.83444405  0.5713439   0.84359246]]\n",
      "8000 0.647395 [[-0.91746962 -2.21966529  0.76009941 -0.69214541  0.38269079]\n",
      " [ 0.39658424 -2.30128932 -0.53919321  0.57053769  0.10539308]] [[ 0.07649061  0.51982284  0.5679633   0.66587132]\n",
      " [-0.85331136 -1.71789896 -0.99227566 -1.7289741 ]\n",
      " [ 0.32902277 -0.82380056  0.56496096  0.38824713]\n",
      " [-0.93815833  0.83258748  0.01968363 -0.87507159]\n",
      " [-0.74026352 -0.85522866  0.55550617  0.81973577]]\n",
      "[array([[ 0.4146758 ],\n",
      "       [ 0.55320662],\n",
      "       [ 0.51647758],\n",
      "       [ 0.55122876]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 1.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [False]], dtype=bool), 0.75]\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "# Use 'Deep' neurals network to solve XOR problem. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0))\n",
    "\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias1\")\n",
    "\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
