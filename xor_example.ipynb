{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR operation by NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.694192 [[ 0.38814735 -0.20966713]\n",
      " [ 0.1806348  -0.375875  ]] [[-0.44491372]\n",
      " [ 0.70176834]]\n",
      "1000 0.693339 [[ 0.32086322 -0.07168127]\n",
      " [ 0.07590109 -0.27049291]] [[-0.41793168]\n",
      " [ 0.61851215]]\n",
      "2000 0.69322 [[ 0.29030085 -0.00923738]\n",
      " [ 0.01765184 -0.22450809]] [[-0.40088201]\n",
      " [ 0.59317988]]\n",
      "3000 0.69318 [[ 0.27482644  0.02630654]\n",
      " [-0.02019913 -0.19851612]] [[-0.39234942]\n",
      " [ 0.58106726]]\n",
      "4000 0.693162 [[ 0.26721501  0.04954347]\n",
      " [-0.04742356 -0.18198174]] [[-0.38752374]\n",
      " [ 0.57454139]]\n",
      "5000 0.693152 [[ 0.26464677  0.06638727]\n",
      " [-0.0686458  -0.1711266 ]] [[-0.3846783 ]\n",
      " [ 0.57098961]]\n",
      "6000 0.693143 [[ 0.26596051  0.07975778]\n",
      " [-0.08650951 -0.16434366]] [[-0.38314295]\n",
      " [ 0.56933081]]\n",
      "7000 0.693135 [[ 0.27079007  0.09132771]\n",
      " [-0.10277356 -0.16093186]] [[-0.38270462]\n",
      " [ 0.56909269]]\n",
      "8000 0.693126 [[ 0.27926892  0.10221041]\n",
      " [-0.11880027 -0.16067655]] [[-0.38341314]\n",
      " [ 0.57011634]]\n",
      "[array([[ 0.50291359],\n",
      "       [ 0.50005174],\n",
      "       [ 0.49992329],\n",
      "       [ 0.49700138]], dtype=float32), array([[ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.],\n",
      "       [ 0.]], dtype=float32), array([[False],\n",
      "       [ True],\n",
      "       [False],\n",
      "       [ True]], dtype=bool), 0.5]\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Implement code for Sung Kim's TF lecture. See https://www.youtube.com/watch?v=9i7FBbcZPMA&feature=youtu.be\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "# Need to change data structure. THESE LINES ARE DIFFERNT FROM Video BUT IT MAKES THIS CODE WORKS!\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform( [2,2], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [2,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 'wide' neural network to solve XOR problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.733474 [[ 0.70221001 -0.53889644  0.11911839 -0.86905229 -0.93228507 -0.8713544\n",
      "  -0.54055244  0.57190865 -0.25249514 -0.40831131]\n",
      " [-0.5210098   0.75651574  0.43360707  0.75772208  0.61628681 -0.37962148\n",
      "   0.90395856  0.04139151 -0.48191801 -0.17461844]] [[-0.93642765]\n",
      " [ 0.65975887]\n",
      " [-0.42310634]\n",
      " [ 0.52158654]\n",
      " [-0.56722403]\n",
      " [-0.73981887]\n",
      " [-0.72574544]\n",
      " [ 0.79894501]\n",
      " [-0.34472358]\n",
      " [ 0.29835099]]\n",
      "1000 0.629403 [[ 1.07106316 -0.85133737  0.05937625 -1.42341197 -0.78972965 -1.63911951\n",
      "  -0.83708769  0.74785751 -0.34079257 -0.36304   ]\n",
      " [-0.50998515  0.55439878  0.46740225  0.79922533  0.95587134 -1.3901459\n",
      "   1.56642306  0.36407518 -0.50718886 -0.17423981]] [[-0.82659197]\n",
      " [ 0.86280787]\n",
      " [-0.27249357]\n",
      " [ 1.04360044]\n",
      " [-0.57415181]\n",
      " [-1.43375754]\n",
      " [-1.13861907]\n",
      " [ 1.08004034]\n",
      " [-0.14067982]\n",
      " [ 0.52612907]]\n",
      "2000 0.262367 [[ 1.71268225 -1.69308043  0.06929957 -3.06719041 -1.01242387 -3.18095994\n",
      "  -2.38301849  1.43026102 -0.34650099 -0.45042449]\n",
      " [-0.79469007  0.81020445  0.54038388  2.04301095  1.76457906 -3.03913975\n",
      "   3.45929193  1.20639384 -0.52859384 -0.39317867]] [[-1.02411127]\n",
      " [ 1.62565374]\n",
      " [-0.15973046]\n",
      " [ 3.01800418]\n",
      " [-1.14011371]\n",
      " [-3.4518404 ]\n",
      " [-3.29046512]\n",
      " [ 1.78995252]\n",
      " [ 0.34937912]\n",
      " [ 1.06449401]]\n",
      "3000 0.0809608 [[ 2.10825896 -2.3934536   0.08344013 -4.21523952 -1.35534    -3.89452887\n",
      "  -3.38022733  1.83568847 -0.34781608 -0.5614723 ]\n",
      " [-0.98707938  1.2020179   0.5771383   2.96263742  2.39433098 -3.74124408\n",
      "   4.65825176  1.6290729  -0.61829597 -0.66941917]] [[-1.22342372]\n",
      " [ 2.34953141]\n",
      " [-0.11676726]\n",
      " [ 4.72091961]\n",
      " [-1.73138297]\n",
      " [-4.43558121]\n",
      " [-5.15409184]\n",
      " [ 2.36457825]\n",
      " [ 0.76323587]\n",
      " [ 1.5772481 ]]\n",
      "4000 0.0402157 [[ 2.29533124 -2.76395416  0.088029   -4.69842052 -1.56936777 -4.18372297\n",
      "  -3.80527663  2.01352763 -0.34916008 -0.61820543]\n",
      " [-1.09107959  1.44962704  0.5902015   3.37040281  2.73442769 -4.02068186\n",
      "   5.14884567  1.80699837 -0.68868518 -0.8319754 ]] [[-1.33576083]\n",
      " [ 2.7628696 ]\n",
      " [-0.09783725]\n",
      " [ 5.56958055]\n",
      " [-2.09577632]\n",
      " [-4.86744738]\n",
      " [-6.07609129]\n",
      " [ 2.65509796]\n",
      " [ 0.9758392 ]\n",
      " [ 1.86847937]]\n",
      "5000 0.0253612 [[ 2.40967655 -2.99620605  0.09026824 -4.96834946 -1.71213758 -4.34677982\n",
      "  -4.04669237  2.11832929 -0.35037971 -0.65934521]\n",
      " [-1.158916    1.61593425  0.59677148  3.60571241  2.95098662 -4.17821789\n",
      "   5.42030525  1.91115677 -0.73969752 -0.94043964]] [[-1.41235733]\n",
      " [ 3.036731  ]\n",
      " [-0.08679573]\n",
      " [ 6.08728981]\n",
      " [-2.34335876]\n",
      " [-5.12328768]\n",
      " [-6.63479996]\n",
      " [ 2.83422112]\n",
      " [ 1.10969782]\n",
      " [ 2.06127787]]\n",
      "6000 0.0180829 [[ 2.49044871 -3.16072679  0.09162534 -5.14740419 -1.81737113 -4.45612144\n",
      "  -4.20868921  2.19084978 -0.351726   -0.69329983]\n",
      " [-1.20869708  1.73853588  0.60080498  3.76496005  3.10595226 -4.28402805\n",
      "   5.59943628  1.98311615 -0.77906084 -1.02085114]] [[-1.47039711]\n",
      " [ 3.23885465]\n",
      " [-0.07928962]\n",
      " [ 6.44986105]\n",
      " [-2.52833891]\n",
      " [-5.30052662]\n",
      " [-7.02432632]\n",
      " [ 2.96070313]\n",
      " [ 1.20579767]\n",
      " [ 2.20409751]]\n",
      "7000 0.013867 [[ 2.55234742 -3.28627992  0.09255107 -5.27832174 -1.90011239 -4.53683281\n",
      "  -4.32814264  2.24571323 -0.35319039 -0.7227639 ]\n",
      " [-1.24783957  1.83469462  0.60357863  3.88300371  3.22507238 -4.36224365\n",
      "   5.72997141  2.03752685 -0.8109749  -1.0844419 ]] [[-1.51711428]\n",
      " [ 3.39810991]\n",
      " [-0.07371736]\n",
      " [ 6.72520542]\n",
      " [-2.67521405]\n",
      " [-5.43447161]\n",
      " [-7.31925488]\n",
      " [ 3.05743122]\n",
      " [ 1.28026235]\n",
      " [ 2.31725502]]\n",
      "8000 0.0111533 [[ 2.60227728 -3.38689041  0.09323078 -5.38008451 -1.96802294 -4.60008097\n",
      "  -4.42160606  2.28959036 -0.35473183 -0.74900079]\n",
      " [-1.28001404  1.91334891  0.60562593  3.97569036  3.32105947 -4.42361593\n",
      "   5.83119965  2.08102965 -0.83777308 -1.13690639]] [[-1.55620873]\n",
      " [ 3.52907062]\n",
      " [-0.06934295]\n",
      " [ 6.94545078]\n",
      " [-2.79667592]\n",
      " [-5.54136086]\n",
      " [-7.55467176]\n",
      " [ 3.13528347]\n",
      " [ 1.34083796]\n",
      " [ 2.41089559]]\n",
      "[array([[ 0.00605645],\n",
      "       [ 0.98954356],\n",
      "       [ 0.98732275],\n",
      "       [ 0.01515269]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use 'wide' neural network (10 neurals) to solve XOR problem. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Wide network: Use more neurons in each layer. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,10], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [10,1], -1.0, 1.0))\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([10]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L2,W2) + b2)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(8001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use 'Deep' neural network to solve XOR problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.733715 [[-0.90483856  0.39183104 -0.80646926  0.48715159 -0.03867198]\n",
      " [-0.98090732  0.39945036  0.73835498  0.63823467  0.64624053]] [[ 0.9423843   0.15881255  0.47409219 -0.28724322]\n",
      " [-0.49680737 -0.48129719 -0.0422513  -0.13418159]\n",
      " [-0.78293115 -0.89813536  0.78211033 -0.42110744]\n",
      " [ 0.35311505 -0.46266755 -0.16855457 -0.78781158]\n",
      " [-0.16092953  0.15618949  0.08073769  0.26624981]]\n",
      "1000 0.692295 [[-0.85716099  0.43061852 -0.9121626   0.53153592 -0.05550944]\n",
      " [-0.93971235  0.41017795  0.65681183  0.65434468  0.6495443 ]] [[ 0.9099291   0.35112122  0.32124013 -0.30948704]\n",
      " [-0.5027045  -0.48166487 -0.05387558 -0.13512751]\n",
      " [-0.79377627 -0.83726209  0.75983828 -0.42540571]\n",
      " [ 0.35112628 -0.48936456 -0.15751441 -0.78551543]\n",
      " [-0.17277393  0.20559324  0.03444846  0.26044434]]\n",
      "2000 0.689509 [[-0.94431549  0.49662146 -1.09612274  0.5951156  -0.07635334]\n",
      " [-0.99529576  0.43714464  0.69347006  0.68266165  0.65419662]] [[ 0.91793668  0.56196362  0.18147701 -0.33218566]\n",
      " [-0.50405532 -0.51541466 -0.03240275 -0.13036901]\n",
      " [-0.79662174 -0.84266442  0.81099033 -0.41894653]\n",
      " [ 0.34826362 -0.55932188 -0.10769968 -0.77622736]\n",
      " [-0.17160475  0.24045235  0.01077818  0.25796545]]\n",
      "3000 0.677302 [[-1.29278982  0.6227355  -1.47505844  0.70913142 -0.1115787 ]\n",
      " [-1.24622416  0.49179679  0.9458977   0.73494631  0.66836715]] [[ 0.99627501  0.93702644 -0.06131257 -0.36591187]\n",
      " [-0.51458865 -0.56948364 -0.01402857 -0.12432513]\n",
      " [-0.83979839 -0.94876093  0.9593882  -0.39888582]\n",
      " [ 0.32667944 -0.66307449 -0.05404922 -0.76502192]\n",
      " [-0.15768796  0.30970889 -0.04501784  0.25301701]]\n",
      "4000 0.579666 [[-2.38603854  0.9109304  -2.5250504   0.96219462 -0.21422566]\n",
      " [-2.04282236  0.54314864  1.75730228  0.79960573  0.83522075]] [[ 1.35616469  1.87069273 -0.70377934 -0.44146079]\n",
      " [-0.52567804 -0.64108789 -0.03616425 -0.11451807]\n",
      " [-1.12285185 -1.4462285   1.51334143 -0.32909709]\n",
      " [ 0.29725623 -0.7847172  -0.04107267 -0.75049007]\n",
      " [-0.03704271  0.59186983 -0.27335069  0.23542506]]\n",
      "5000 0.162578 [[-3.92008233  1.22053158 -4.34072685  1.23506999 -1.05880737]\n",
      " [-3.06127739  0.29910496  2.96858764  0.71136707  3.07635856]] [[ 1.89003587  2.79105639 -1.62318182 -0.56343353]\n",
      " [-0.58550441 -0.69445264  0.21957947 -0.08272696]\n",
      " [-1.78756273 -2.67473602  2.68662739 -0.15823664]\n",
      " [ 0.28372687 -0.74453318  0.14476062 -0.72587097]\n",
      " [ 0.94197005  2.46503091 -1.79658282  0.05055793]]\n",
      "6000 0.0299567 [[-4.28130817  1.2716912  -4.99080658  1.31287992 -1.73282695]\n",
      " [-3.46557808  0.31198004  3.55002761  0.74154681  4.22468185]] [[ 2.08898592  3.0605526  -2.03016734 -0.61664313]\n",
      " [-0.67285818 -0.79653168  0.40717426 -0.05409417]\n",
      " [-2.20877957 -3.51379156  3.34923267 -0.04787682]\n",
      " [ 0.20399302 -0.83851004  0.32351881 -0.69717193]\n",
      " [ 1.55294275  3.40965128 -2.79925823 -0.07026748]]\n",
      "7000 0.0138217 [[-4.39049149  1.2841934  -5.21717453  1.3375814  -1.98664212]\n",
      " [-3.60446668  0.3362543   3.73586512  0.7622571   4.56651497]] [[  2.15543485e+00   3.14033270e+00  -2.16266227e+00  -6.35497689e-01]\n",
      " [ -7.06691742e-01  -8.26558173e-01   4.65257853e-01  -4.00912352e-02]\n",
      " [ -2.38647842e+00  -3.83042717e+00   3.61756063e+00   7.13115325e-04]\n",
      " [  1.70954257e-01  -8.69215667e-01   3.82726520e-01  -6.82628274e-01]\n",
      " [  1.78475857e+00   3.72055054e+00  -3.14951396e+00  -1.15176618e-01]]\n",
      "8000 0.00861296 [[-4.44884348  1.2907182  -5.34366941  1.35105598 -2.1299684 ]\n",
      " [-3.6803422   0.35291123  3.83565211  0.77534723  4.74809742]] [[ 2.19170952  3.18096066 -2.23290014 -0.64622772]\n",
      " [-0.72626573 -0.84271669  0.49652654 -0.03083179]\n",
      " [-2.49355817 -4.00976133  3.77514195  0.0310244 ]\n",
      " [ 0.1517406  -0.88573366  0.41491935 -0.67302281]\n",
      " [ 1.92162299  3.89383078 -3.34678531 -0.14176546]]\n",
      "9000 0.00614979 [[-4.48735332  1.29506302 -5.42924166  1.3600769  -2.22715592]\n",
      " [-3.73087811  0.36531064  3.90170503  0.78473663  4.86767626]] [[ 2.2159605   3.20693064 -2.27882504 -0.65362394]\n",
      " [-0.73983985 -0.85356736  0.51728338 -0.02384986]\n",
      " [-2.56946588 -4.13183022  3.88479805  0.05306926]\n",
      " [ 0.13841464 -0.89674336  0.43634146 -0.66579783]\n",
      " [ 2.01763797  4.0112443  -3.48103762 -0.16053794]]\n",
      "10000 0.0047401 [[-4.51561308  1.2983048  -5.49308014  1.36676955 -2.29967999]\n",
      " [-3.76814961  0.37512431  3.95028758  0.79200077  4.95533466]] [[ 2.23392773  3.22555017 -2.31225395 -0.65923786]\n",
      " [-0.75016749 -0.86167109  0.53258902 -0.01821206]\n",
      " [-2.62803388 -4.22324181  3.96819067  0.07042698]\n",
      " [ 0.12828673 -0.90490288  0.45214194 -0.65997738]\n",
      " [ 2.09120226  4.09903336 -3.58165264 -0.17502148]]\n",
      "11000 0.00383586 [[-4.53771305  1.30088818 -5.54360723  1.37204766 -2.35705328]\n",
      " [-3.79738498  0.38322112  3.98834682  0.79789907  5.02383947]] [[ 2.24808526  3.23985124 -2.33821416 -0.66375101]\n",
      " [-0.75847465 -0.86811018  0.54460675 -0.01346528]\n",
      " [-2.6756165  -4.29578495  4.03514338  0.08476749]\n",
      " [ 0.12015111 -0.91134101  0.4645412  -0.6550864 ]\n",
      " [ 2.1506505   4.16866302 -3.66157627 -0.18680654]]\n",
      "12000 0.00321027 [[-4.55573368  1.30303276 -5.58520222  1.37638485 -2.40425611]\n",
      " [-3.82128191  0.39010075  4.0194416   0.80285031  5.07969332]] [[ 2.25970531  3.25134778 -2.35926175 -0.66752034]\n",
      " [-0.7654081  -0.8734377   0.55444419 -0.00935465]\n",
      " [-2.71563625 -4.35563326  4.0908947   0.09700288]\n",
      " [ 0.11336945 -0.91663563  0.47468153 -0.65085763]\n",
      " [ 2.20043778  4.22611094 -3.72758031 -0.1967409 ]]\n",
      "13000 0.0027535 [[-4.57087183  1.30486083 -5.62043428  1.38005459 -2.44419742]\n",
      " [-3.84139323  0.39607471  4.04560232  0.80710852  5.12662411]] [[ 2.26952124  3.26089406 -2.376858   -0.67075449]\n",
      " [-0.77135074 -0.87797391  0.56273884 -0.00572226]\n",
      " [-2.75014043 -4.40640306  4.13854456  0.10768496]\n",
      " [ 0.10756525 -0.92111892  0.48322248 -0.64712703]\n",
      " [ 2.24320984  4.27485037 -3.78362083 -0.20532861]]\n",
      "14000 0.00240628 [[-4.58389044  1.30646253 -5.65090227  1.38322055 -2.47871614]\n",
      " [-3.85870075  0.40134951  4.0681119   0.81083781  5.16695309]] [[  2.27800155e+00   3.26901817e+00  -2.39191294e+00  -6.73584998e-01]\n",
      " [ -7.76544809e-01  -8.81917655e-01   5.69888473e-01  -2.46328255e-03]\n",
      " [ -2.78044868e+00  -4.45037746e+00   4.18008518e+00   1.17173046e-01]\n",
      " [  1.02498315e-01  -9.24998045e-01   4.90576327e-01  -6.43783450e-01]\n",
      " [  2.28066611e+00   4.31707859e+00  -3.83220291e+00  -2.12893113e-01]]\n",
      "15000 0.00213398 [[-4.59526777  1.30787659 -5.67769194  1.38600457 -2.50904083]\n",
      " [-3.87384868  0.4060688   4.08782291  0.81415302  5.20222282]] [[  2.28545213e+00   3.27605772e+00  -2.40502620e+00  -6.76100850e-01]\n",
      " [ -7.81154394e-01  -8.85403574e-01   5.76157629e-01   4.95540909e-04]\n",
      " [ -2.80746031e+00  -4.48909378e+00   4.21685362e+00   1.25714183e-01]\n",
      " [  9.80066657e-02  -9.28411543e-01   4.97016758e-01  -6.40750945e-01]\n",
      " [  2.31395793e+00   4.35427380e+00  -3.87500381e+00  -2.19654173e-01]]\n",
      "16000 0.00191507 [[-4.60533857  1.30914903 -5.7015667   1.38848662 -2.53603411]\n",
      " [-3.88728833  0.41033655  4.10531998  0.81713372  5.23348331]] [[  2.29207897e+00   3.28225374e+00  -2.41660380e+00  -6.78366065e-01]\n",
      " [ -7.85296559e-01  -8.88524592e-01   5.81730783e-01   3.20758484e-03]\n",
      " [ -2.83181429e+00  -4.52361631e+00   4.24980736e+00   1.33485660e-01]\n",
      " [  9.39757377e-02  -9.31456506e-01   5.02735078e-01  -6.37975216e-01]\n",
      " [  2.34390545e+00   4.38744593e+00  -3.91320062e+00  -2.25767538e-01]]\n",
      "17000 0.00173543 [[-4.61438084  1.31030977 -5.72305155  1.39071715 -2.56032085]\n",
      " [-3.8993454   0.41422972  4.12101793  0.8198384   5.26151991]] [[ 2.29804087  3.28775978 -2.42695332 -0.68042511]\n",
      " [-0.78905463 -0.89134765  0.58673847  0.00571282]\n",
      " [-2.85398054 -4.55472708  4.27963066  0.14061864]\n",
      " [ 0.09032204 -0.93419981  0.50786793 -0.63541281]\n",
      " [ 2.37110114  4.4173646  -3.94765139 -0.23134811]]\n",
      "18000 0.00158553 [[-4.62258577  1.31138265 -5.74257708  1.39274621 -2.58237171]\n",
      " [-3.91026807  0.41780838  4.13525343  0.82231295  5.28689766]] [[ 2.30346012  3.29272175 -2.43629432 -0.68231481]\n",
      " [-0.79249346 -0.89392501  0.59128183  0.00804218]\n",
      " [-2.87431788 -4.58302355  4.30685329  0.1472135 ]\n",
      " [ 0.08698232 -0.9366954   0.51252091 -0.6330319 ]\n",
      " [ 2.39600587  4.44458437 -3.97899485 -0.23648235]]\n",
      "19000 0.00145865 [[-4.6300292   1.31234205 -5.76044893  1.39459968 -2.60253906]\n",
      " [-3.92023134  0.4211179   4.14821959  0.82459319  5.31005859]] [[ 2.30841064  3.29721785 -2.44478655 -0.68405604]\n",
      " [-0.79566139 -0.89629281  0.59543484  0.01021997]\n",
      " [-2.89310098 -4.60893917  4.33188009  0.15334842]\n",
      " [ 0.08390811 -0.93898368  0.51676869 -0.63081062]\n",
      " [ 2.41896796  4.4695158  -4.00772524 -0.24123766]]\n",
      "20000 0.00134993 [[-4.63689327  1.31326139 -5.77691841  1.3963114  -2.62110806]\n",
      " [-3.929389    0.42419583  4.16015434  0.82670575  5.33131218]] [[ 2.31298852  3.30134892 -2.45257235 -0.68567514]\n",
      " [-0.79860002 -0.89848572  0.59925663  0.01226569]\n",
      " [-2.91055131 -4.63283777  4.35501575  0.15908545]\n",
      " [ 0.08106136 -0.94109327  0.52067369 -0.62872362]\n",
      " [ 2.44025874  4.49252605 -4.03423357 -0.24566683]]\n",
      "[array([[  5.75442042e-04],\n",
      "       [  9.98800039e-01],\n",
      "       [  9.98338461e-01],\n",
      "       [  1.95858511e-03]], dtype=float32), array([[ 0.],\n",
      "       [ 1.],\n",
      "       [ 1.],\n",
      "       [ 0.]], dtype=float32), array([[ True],\n",
      "       [ True],\n",
      "       [ True],\n",
      "       [ True]], dtype=bool), 1.0]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Use 'Deep' neural network to solve XOR problem. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "xy = np.loadtxt('xor_dataset.txt', unpack=True)\n",
    "\n",
    "x_data = np.transpose( xy[0:-1] )\n",
    "y_data = np.reshape( xy[-1], (4,1) )\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Deep network configuration.: Use more layers. \n",
    "W1 = tf.Variable(tf.random_uniform( [2,5], -1.0, 1.0))\n",
    "W2 = tf.Variable(tf.random_uniform( [5,4], -1.0, 1.0))\n",
    "W3 = tf.Variable(tf.random_uniform( [4,1], -1.0, 1.0))\n",
    "\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name=\"Bias1\")\n",
    "b2 = tf.Variable(tf.zeros([4]), name=\"Bias2\")\n",
    "b3 = tf.Variable(tf.zeros([1]), name=\"Bias3\")\n",
    "\n",
    "\n",
    "# Hypotheses \n",
    "L2 =  tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "L3 =  tf.sigmoid(tf.matmul(L2,W2)+b2)\n",
    "hypothesis = tf.sigmoid( tf.matmul(L3,W3) + b3)\n",
    "\n",
    "# Cost function \n",
    "cost = -tf.reduce_mean( Y*tf.log(hypothesis)+(1-Y)* tf.log(1.-hypothesis) )\n",
    "\n",
    "# Minimize cost.\n",
    "a = tf.Variable(0.1)\n",
    "optimizer = tf.train.GradientDescentOptimizer(a)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Initializa all variables.\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for step in range(20001):\n",
    "        sess.run(train, feed_dict={X:x_data, Y:y_data})\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(\n",
    "                step, \n",
    "                sess.run(cost, feed_dict={X:x_data, Y:y_data}), \n",
    "                sess.run(W1),\n",
    "                sess.run(W2)\n",
    "            )\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal( tf.floor(hypothesis+0.5), Y)\n",
    "    accuracy = tf.reduce_mean(tf.cast( correct_prediction, \"float\" ) )\n",
    "    \n",
    "    # Check accuracy\n",
    "    print( sess.run( [hypothesis, tf.floor(hypothesis+0.5), correct_prediction, accuracy], \n",
    "                   feed_dict={X:x_data, Y:y_data}) )\n",
    "    print( \"Accuracy:\", accuracy.eval({X:x_data, Y:y_data}) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
